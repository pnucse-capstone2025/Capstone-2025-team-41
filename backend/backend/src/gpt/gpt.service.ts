// src/gpt/gpt.service.ts

import { Inject, Injectable, Logger } from "@nestjs/common";
import { CACHE_MANAGER } from "@nestjs/cache-manager";
import { Cache } from "cache-manager";
import OpenAI from "openai";
import * as dotenv from "dotenv";
import { KeywordMapService } from "../services/keyword-map.service";

dotenv.config();

@Injectable()
export class GptService {
  private readonly logger = new Logger(GptService.name);
  private readonly openai: OpenAI;

  private readonly MODEL = process.env.GPT_MODEL?.trim() || "gpt-3.5-turbo";
  private readonly MAX_RETURN = Number(process.env.GPT_KEYWORD_MAX_RETURN ?? 5);
  private readonly CACHE_TTL_SEC = Number(
    process.env.GPT_KEYWORD_CACHE_TTL_SEC ?? 3600,
  ); // Í∏∞Î≥∏ 1ÏãúÍ∞Ñ

  constructor(
    private readonly keywordMapService: KeywordMapService,
    @Inject(CACHE_MANAGER) private readonly cacheManager: Cache,
  ) {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
  }

  async extractKeywords(sentence: string): Promise<string[]> {
    const normalized = sentence.trim();
    const cacheKey = `gpt:keywords:${normalized}`;

    // 1. Ï∫êÏãú ÌôïÏù∏
    try {
      const cached = await this.cacheManager.get<string[]>(cacheKey);
      if (cached) {
        this.logger.log(`üß† [HIT] Cache ÏÇ¨Ïö©: "${cacheKey}"`);
        return cached;
      }
    } catch (err) {
      this.logger.warn(`‚ö†Ô∏è Cache Ï°∞Ìöå Ïã§Ìå®: ${err}`);
    }

    // 2. GPT ÌîÑÎ°¨ÌîÑÌä∏ Íµ¨ÏÑ±
    let prompt = "";
    let candidateList: string[] = [];
    const fullKeyList = Array.from(this.keywordMapService.getMap().keys());

    try {
      candidateList = this.keywordMapService.searchKeywords(normalized, 50);
      this.logger.log(`üîë ÌõÑÎ≥¥ KEYÎ™©Î°ù ${candidateList.length}Í∞ú ÏÑ†ÌÉù`);

      prompt = [
        "ÎÑàÎäî ÏùåÏãù/ÏãùÎãπ ÌÇ§ÏõåÎìú Îß§ÌçºÎã§.",
        "ÏïÑÎûò KEYÎ™©Î°ù Ï§ëÏóêÏÑú ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìïú Îã®Ïñ¥ÏôÄ Í∞ÄÏû• Ïó∞Í¥ÄÎêú ÌÇ§ÏõåÎìú 1~5Í∞úÎ•º JSON Î∞∞Ïó¥Î°ú Ï∂úÎ†•ÌïòÎùº.",
        "‚ö†Ô∏è ÏûÖÎ†• Îã®Ïñ¥Í∞Ä KEYÎ™©Î°ùÏóê ÏûàÏúºÎ©¥ Í∑∏ÎåÄÎ°ú ÏÑ†ÌÉùÌï¥ÎèÑ ÎêúÎã§.",
        "‚ö†Ô∏è ÏûÖÎ†• Îã®Ïñ¥Í∞Ä Î™©Î°ùÏóê ÏóÜÏúºÎ©¥ Í∞ÄÏû• Í∞ÄÍπåÏö¥ ÏùòÎØ∏Ïùò ÌÇ§ÏõåÎìúÎ•º Í≥®ÎùºÏïº ÌïúÎã§.",
        "‚ö†Ô∏è KEYÎ™©Î°ùÏóê Ï†ÑÌòÄ ÏóÜÏúºÎ©¥, ÏÉàÎ°úÏö¥ Ïó∞Í¥Ä ÌÇ§ÏõåÎìúÎ•º ÏßÅÏ†ë ÎßåÎì§Ïñ¥ÎèÑ ÎêúÎã§.",
        "‚ö†Ô∏è Î∞òÎìúÏãú JSON Î∞∞Ïó¥Îßå Î∞òÌôòÌï¥Ïïº ÌïúÎã§. Ïòà: [\"ÏÇºÍ≤πÏÇ¥\", \"Í≥†Í∏∞\"]",
        `KEYÎ™©Î°ù: ${JSON.stringify(candidateList)}`,
        `ÏÇ¨Ïö©Ïûê ÏûÖÎ†•: "${normalized}"`,
      ].join("\n");
    } catch (err) {
      this.logger.error("‚ùå KEYÎ™©Î°ù Íµ¨ÏÑ± Ïã§Ìå®", err as any);
      throw new Error("KEYÎ™©Î°ù Íµ¨ÏÑ± Ïã§Ìå®");
    }

    let keywords: string[] = [];

    // 3. GPT Ìò∏Ï∂ú
    try {
      this.logger.log(`ü§ñ GPT Ìò∏Ï∂ú ÏãúÏûë (model: ${this.MODEL})`);
      const response = await this.openai.chat.completions.create({
        model: this.MODEL,
        messages: [
          { role: "system", content: "ÎÑàÎäî ÏùåÏãù/ÏãùÎãπ ÌÇ§ÏõåÎìú Îß§ÌçºÎã§." },
          { role: "user", content: prompt },
        ],
        temperature: 0,
        max_tokens: 150,
      });

      const raw = response.choices[0]?.message?.content?.trim() ?? "[]";
      this.logger.debug(`üì• GPT raw=${raw}`);
      keywords = this.parseKeywordsFromResponse(raw);

      // ‚úÖ Îçî Ïù¥ÏÉÅ DB ÍµêÏ∞® ÌïÑÌÑ∞ÎßÅ Ïïà Ìï®
      if (!Array.isArray(keywords) || keywords.length === 0) {
        this.logger.warn(`‚ö†Ô∏è GPT ÏùëÎãµ Î¨¥Ìö®, fallback ÏÇ¨Ïö©. raw="${raw}"`);
        keywords = this.keywordMapService.searchKeywords(
          normalized,
          this.MAX_RETURN,
        );
      }
    } catch (err) {
      this.logger.error("‚ùå GPT Ìò∏Ï∂ú Ïã§Ìå®, fallback ÏÇ¨Ïö©", err as any);
      keywords = this.keywordMapService.searchKeywords(
        normalized,
        this.MAX_RETURN,
      );
    }

    // 4. Ï†ïÍ∑úÌôî + Ï§ëÎ≥µ Ï†úÍ±∞
    keywords = this.normalizeKeywordList(keywords).slice(0, this.MAX_RETURN);

    // 5. Ï∫êÏãúÏóê Ï†ÄÏû•
    try {
      await this.cacheManager.set(cacheKey, keywords, this.CACHE_TTL_SEC);
      this.logger.log(`‚úÖ [SET] Cache Ï†ÄÏû• ÏôÑÎ£å: "${cacheKey}"`);
    } catch (err) {
      this.logger.warn(`‚ö†Ô∏è Cache Ï†ÄÏû• Ïã§Ìå®: ${err}`);
    }

    return keywords;
  }

  // -------------------- ÎÇ¥Î∂Ä Ïú†Ìã∏ --------------------

  private parseKeywordsFromResponse(raw: string): string[] {
    try {
      const match = raw.match(/\[.*\]/s);
      if (match) {
        const arr = JSON.parse(match[0]);
        if (Array.isArray(arr)) {
          const parsed = arr.map(String);
          this.logger.debug(`‚úÖ GPT ÌååÏã± Í≤∞Í≥º: ${JSON.stringify(parsed)}`);
          return parsed;
        }
      }
    } catch (err) {
      this.logger.warn(`‚ö†Ô∏è GPT ÏùëÎãµ JSON ÌååÏã± Ïã§Ìå®: ${err}`);
    }

    if (raw.includes(",")) {
      const fallbackParsed = raw
        .split(",")
        .map((s) => s.trim().replace(/^"|"$/g, ""))
        .filter(Boolean);
      this.logger.debug(
        `üîÅ ÏâºÌëú Í∏∞Î∞ò fallback ÌååÏã± Í≤∞Í≥º: ${JSON.stringify(fallbackParsed)}`,
      );
      return fallbackParsed;
    }

    const only = raw.replace(/^\[|\]$/g, "").trim().replace(/^"|"$/g, "");
    return only ? [only] : [];
  }

  private normalizeKeywordList(arr: unknown[]): string[] {
    const seen = new Set<string>();
    const out: string[] = [];
    for (const v of arr) {
      if (v == null) continue;
      const s = String(v).trim();
      if (!s || seen.has(s)) continue;
      seen.add(s);
      out.push(s);
    }
    return out;
  }
}
