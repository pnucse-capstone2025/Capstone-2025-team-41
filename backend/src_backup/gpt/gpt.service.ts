import {
  Inject,
  Injectable,
  Logger,
} from '@nestjs/common';
import { CACHE_MANAGER } from '@nestjs/cache-manager'; // ‚úÖ Ïò¨Î∞îÎ•∏ ÏúÑÏπòÏóêÏÑú import
import { Cache } from 'cache-manager';
import OpenAI from 'openai';
import * as dotenv from 'dotenv';

dotenv.config();

@Injectable()
export class GptService {
  private readonly logger = new Logger(GptService.name);
  private readonly openai: OpenAI;

  private readonly MODEL = process.env.GPT_MODEL?.trim() || 'gpt-3.5-turbo';
  private readonly MAX_RETURN = Number(process.env.GPT_KEYWORD_MAX_RETURN ?? 5);
  private readonly CACHE_TTL_SEC = Number(process.env.GPT_KEYWORD_CACHE_TTL_SEC ?? 3600); // Í∏∞Î≥∏ 1ÏãúÍ∞Ñ

  constructor(
    @Inject(CACHE_MANAGER) private readonly cacheManager: Cache,
  ) {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
  }

  async extractKeywords(sentence: string): Promise<string[]> {
    const normalized = sentence.trim();
    const cacheKey = `gpt:keywords:${normalized}`;

    // ‚úÖ 1. Ï∫êÏãú ÌôïÏù∏
    try {
      const cached = await this.cacheManager.get<string[]>(cacheKey);
      if (cached) {
        this.logger.log(`üß† [HIT] Cache ÏÇ¨Ïö©: "${cacheKey}"`);
        return cached;
      }
    } catch (err) {
      this.logger.warn(`‚ö†Ô∏è Cache Ï°∞Ìöå Ïã§Ìå®: ${err}`);
    }

    // ‚úÖ 2. GPT ÌîÑÎ°¨ÌîÑÌä∏ Íµ¨ÏÑ±
    const prompt = [
      'Îã§Ïùå Î¨∏Ïû•ÏóêÏÑú ÏùåÏãùÏ†ê Ï∂îÏ≤úÏóê Ïú†Ïö©Ìïú ÌïµÏã¨ Í≤ÄÏÉâ ÌÇ§ÏõåÎìúÎßå ÎΩëÏïÑÏ§ò.',
      'Î∞òÎìúÏãú JSON Î∞∞Ïó¥ ÌòïÌÉúÎ°úÎßå ÏùëÎãµÌï¥. Ïòà: ["ÏÇºÍ≤πÏÇ¥","Í≥†Í∏∞","Íµ¨Ïù¥","Ïã†ÏÑ†","ÎßõÏßë"]',
      `Î¨∏Ïû•: "${normalized}"`,
      `ÏµúÎåÄ ${this.MAX_RETURN}Í∞úÎ°ú Ï†úÌïú.`,
    ].join('\n');

    let keywords: string[] = [];

    // ‚úÖ 3. GPT Ìò∏Ï∂ú
    try {
      this.logger.log(`ü§ñ GPT Ìò∏Ï∂ú ÏãúÏûë (model: ${this.MODEL})`);
      const response = await this.openai.chat.completions.create({
        model: this.MODEL,
        messages: [
          {
            role: 'system',
            content:
              'ÎÑàÎäî ÏùåÏãùÏ†ê/ÎßõÏßë Í≤ÄÏÉâ ÌÇ§ÏõåÎìú Ï∂îÏ∂ú Ï†ÑÎ¨∏Í∞ÄÎã§. Î∞òÎìúÏãú JSON Î∞∞Ïó¥Î°úÎßå Ï∂úÎ†•Ìï¥.',
          },
          { role: 'user', content: prompt },
        ],
        temperature: 0.3,
      });

      const raw = response.choices[0]?.message?.content?.trim() ?? '[]';
      keywords = this.parseKeywordsFromResponse(raw);

      if (!Array.isArray(keywords) || keywords.length === 0) {
        this.logger.warn(`‚ö†Ô∏è GPT ÏùëÎãµ ÌååÏã± Ïã§Ìå®, fallback ÏÇ¨Ïö©. raw="${raw}"`);
        keywords = this.simpleFallbackExtract(normalized);
      }
    } catch (err) {
      this.logger.error('‚ùå GPT Ìò∏Ï∂ú Ïã§Ìå®, fallback ÏÇ¨Ïö©', err as any);
      keywords = this.simpleFallbackExtract(normalized);
    }

    // ‚úÖ 4. Ï†ïÍ∑úÌôî + Ï§ëÎ≥µ Ï†úÍ±∞
    keywords = this.normalizeKeywordList(keywords).slice(0, this.MAX_RETURN);

    // ‚úÖ 5. Ï∫êÏãúÏóê Ï†ÄÏû• (TTLÏùÄ Ïà´ÏûêÎ°ú ÏßÅÏ†ë Ï†ÑÎã¨!)
    try {
      await this.cacheManager.set(cacheKey, keywords, this.CACHE_TTL_SEC);
      this.logger.log(`‚úÖ [SET] Cache Ï†ÄÏû• ÏôÑÎ£å: "${cacheKey}"`);
    } catch (err) {
      this.logger.warn(`‚ö†Ô∏è Cache Ï†ÄÏû• Ïã§Ìå®: ${err}`);
    }

    return keywords;
  }

  // -------------------- ÎÇ¥Î∂Ä Ïú†Ìã∏ --------------------

  private parseKeywordsFromResponse(raw: string): string[] {
    try {
      const start = raw.indexOf('[');
      const end = raw.lastIndexOf(']');
      if (start !== -1 && end !== -1 && end > start) {
        const json = raw.substring(start, end + 1);
        const arr = JSON.parse(json);
        if (Array.isArray(arr)) return arr.map(String);
      }
    } catch {
      // fallback ÏïÑÎûòÏóêÏÑú Ï≤òÎ¶¨
    }

    // ÏâºÌëú Í∏∞Î∞ò ÌååÏã± fallback
    if (raw.includes(',')) {
      return raw
        .split(',')
        .map((s) => s.trim().replace(/^"|"$/g, ''))
        .filter(Boolean);
    }

    // Îã®Ïùº ÌÇ§ÏõåÎìú fallback
    const only = raw.replace(/^\[|\]$/g, '').trim().replace(/^"|"$/g, '');
    return only ? [only] : [];
  }

  private simpleFallbackExtract(sentence: string): string[] {
    const tokens = sentence
      .split(/[\s,.;:"'()\-!?]+/)
      .map((w) => w.trim())
      .filter(Boolean);

    const kor = tokens.filter((w) => /^[Í∞Ä-Ìû£]{2,}$/.test(w));
    const eng = tokens.filter((w) => /^[A-Za-z]{3,}$/.test(w));
    const merged = [...kor, ...eng];

    return this.normalizeKeywordList(merged).slice(0, this.MAX_RETURN);
  }

  private normalizeKeywordList(arr: unknown[]): string[] {
    const seen = new Set<string>();
    const out: string[] = [];
    for (const v of arr) {
      if (v == null) continue;
      const s = String(v).trim();
      if (!s || seen.has(s)) continue;
      seen.add(s);
      out.push(s);
    }
    return out;
  }
}
